<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=4321&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.130.0">


<title>Towards ML-literate dystopian fiction - Seth Ariel Green&#39;s website</title>
<meta property="og:title" content="Towards ML-literate dystopian fiction - Seth Ariel Green&#39;s website">


  <link href='http://localhost:4321/favicon.ico' rel='icon' type='image/x-icon'/>



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">

<script defer data-domain="setharielgreen.com" src="https://plausible.io/js/plausible.js"></script>


  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/">Home</a></li>
    
    <li><a href="/blog/">Blog</a></li>
    
    <li><a href="/portfolio/">Portfolio</a></li>
    
    <li><a href="/other-selves/">Other media</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    

    <h1 class="article-title">Towards ML-literate dystopian fiction</h1>

    

    <div class="article-content">
      


<p>My favorite moment in <em>M3gan</em> comes when Allison Williams says to the title character: “I know you think you’re maximizing your <a href="http://kronosapiens.github.io/blog/2017/03/28/objective-functions-in-machine-learning.html">objective function</a>.” it was fun to hear an explicit nod to the language of AI-alignment; someone who worked on this movie reads LessWrong, or talked to people who do.</p>
<p><em>M3gan</em> could serve as a great prequel to an AI apocalypse movie (though I think it’s unlikely). But thinking those movies over – <em>Terminator</em>, <em>Oblivion</em>, <em>The Matrix</em> – they’re mostly action movies that come down to a test of strength. The robots basically think and act like humans, albeit more indestructible.</p>
<p>Meanwhile, Generalized Pretrained Models are more and more a part of our lives, and what sticks out to me about them is their <em>weirdness</em>. Kevin Roose’s <a href="https://www.nytimes.com/2023/02/17/opinion/letters/bing-chatbot-kevin-roose.html">chat with Sydney</a> makes her seem vaguely dangerous but mostly just unhinged. <a href="https://www.wired.com/2016/03/two-moves-alphago-lee-sedol-redefined-future/">AlphaGo’s Move 37 in a championship Go game</a> was weird enough to induce a 15 minute break in the game. An ugly t-shirt can utterly confound <a href="https://www.wired.co.uk/article/facial-recognition-t-shirt-block">facial recognition software and render its wearer invisible</a>.</p>
<p>Let’s forecast these developments 10, 20, 50 years in the future. Imagine that AI has gotten a lot smarter and more dangerous, but basically followed an evolutionary path from today’s machine learning algorithms.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> Imagine further that it <em>inherited the quirks of its ancestors</em>, the way we retain our appendixes and our proclivity to identify every startling noise as a tiger in the brush. How would you outwit such an adversary? What sorts of maneuvers would you pursue? And what clever, weird things would work against a computer but not against a human, the way <a href="https://www.ft.com/content/175e5314-a7f7-4741-a786-273219f433a1">Kellin Pelrine distracted AlphaGo</a>?</p>
<p>A malevolent, omni-rational AI with access to nanotech would be an insurmountable opponent. But a bounded thing with evolutionary heritage, we could deceive, negotiate with, or fight. I’d love to see someone up-to-date on ML research take a crack at writing or visualizing what this might look like.</p>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>Some experts dispute that this is <a href="https://twitter.com/ylecun/status/1621805604900585472">likely or even possible</a>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

    </div>
  </article>

<script src="https://giscus.app/client.js"
        data-repo="setgree/setharielgreen"
        data-repo-id="MDEwOlJlcG9zaXRvcnkyNjU5NTI4MzM="
        data-category="Blog Comments"
        data-category-id="DIC_kwDOD9oeQc4CjbFs"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
      <a href="" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    

    
  


  </body>
</html>

